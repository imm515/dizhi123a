name: 4 Selenium Test IPv6

on:
workflow_dispatch:
inputs:
max_ipv6_count:
description: 'èšåˆæ–‡ä»¶ myIPv6.txt ä¸­ä¿ç•™çš„æœ€å¤§ IPv6 æ¡æ•°ã€‚'
required: false
default: '500' # é»˜è®¤å€¼ 500
type: string

jobs:
fetch_and_sync_ipv6:
runs-on: ubuntu-latest
env:
# âš ï¸ ç¡®ä¿åœ¨ TARGET_REPO ä»“åº“ä¸­æ­£ç¡®é…ç½®äº†ä»¥ä¸‹ Secrets:
# IPV6_SOURCE_URLS: åŒ…å«è¦æŠ“å–çš„ IPv6 åˆ—è¡¨ URLï¼Œæ¯è¡Œä¸€ä¸ªã€‚
# TARGET_REPO: ç›®æ ‡ä»“åº“çš„ owner/repo æ ¼å¼ï¼Œå¦‚ 'user/repo'ã€‚
# TARGET_PAT: å…·æœ‰å¯¹ç›®æ ‡ä»“åº“å†™æƒé™çš„ Personal Access Tokenã€‚
# TARGET_FOLDER: ç›®æ ‡ä»“åº“ä¸­å­˜æ”¾æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚ 'ipv6_lists'ã€‚
TZ: Asia/Shanghai
# è®¾ç½®èšåˆæ–‡ä»¶ä¿ç•™çš„æœ€å¤§ IPv6 æ¡æ•° (ä» input æˆ–é»˜è®¤å€¼è·å–)
MAX_IPV6_COUNT: ${{ github.event.inputs.max_ipv6_count || '500' }}

steps:
  - name: ğŸ“¥ Checkout repository
    uses: actions/checkout@v4
    with:
      fetch-depth: 0

  - name: âš™ï¸ Set Git Credentials
    run: |
      git config --global user.name "github-actions[bot]"
      git config --global user.email "github-actions[bot]@users.noreply.github.com"
      
  # --- æ–°å¢æ­¥éª¤ï¼šå®‰è£… Python, Selenium å’Œ Chrome ---
  - name: ğŸ Set up Python
    uses: actions/setup-python@v5
    with:
      python-version: '3.x'

  - name: âš™ï¸ Install Chrome Browser and Dependencies
    run: |
      # ç¡®ä¿å®‰è£…äº† Chrome å’Œå¿…è¦çš„ä¾èµ–ï¼Œä»¥ä¾› Selenium ä½¿ç”¨
      sudo apt-get update
      sudo apt-get install -y google-chrome-stable
      
  - name: âš™ï¸ Install Python Libraries (Selenium, WebDriver Manager & dateutil)
    run: |
      # dateutil æ˜¯èšåˆè„šæœ¬ä¸­ç”¨äºæ—¥æœŸæ—¶é—´è§£æçš„å…³é”®åº“
      pip install selenium webdriver-manager python-dateutil
  # ---------------------------------------------

  - name: ğŸŒ Fetch IPv6 Addresses and Save (using Selenium)
    id: fetch
    env:
      URL_LIST: ${{ secrets.IPV6_SOURCE_URLS }}
      GITHUB_OUTPUT: ${{ steps.fetch.outputs }} # æ³¨å…¥ GITHUB_OUTPUT è·¯å¾„
    run: |
      echo "Start fetching IPv6 sources using Selenium..."
      
      python3 - <<'PY'
      import os
      import sys
      import time
      from pathlib import Path
      from urllib.parse import urlparse
      
      # å¯¼å…¥ Selenium åº“
      from selenium import webdriver
      from selenium.webdriver.chrome.service import Service
      from selenium.webdriver.chrome.options import Options
      from selenium.webdriver.support.ui import WebDriverWait
      from selenium.webdriver.support import expected_conditions as EC
      from selenium.webdriver.common.by import By
      from webdriver_manager.chrome import ChromeDriverManager
      
      # 1. Configuration and Setup
      URL_LIST = os.environ.get('URL_LIST', '').strip()
      TARGET_DIR = Path('./ipv6_fetch_temp')
      COMMIT_DETAILS_BODY_FILE = Path("commit_details_body.txt")
      # final_commit_message.txt å†™å…¥ä»“åº“æ ¹ç›®å½•
      COMMIT_MESSAGE_FILE = Path("final_commit_message.txt") 
      GITHUB_OUTPUT = os.environ.get('GITHUB_OUTPUT')
      
      if not URL_LIST:
          print("WARNING: IPV6_SOURCE_URLS is empty. Skipping fetch operation.")
          with open(GITHUB_OUTPUT, "a") as f:
              f.write(f"files_created=0\n")
          COMMIT_MESSAGE_FILE.write_text("Skipped due to empty URL list.\n")
          sys.exit(0)

      TARGET_DIR.mkdir(parents=True, exist_ok=True)
      COMMIT_DETAILS_BODY_FILE.write_text("")
      
      urls = [url.strip() for url in URL_LIST.splitlines() if url.strip()]
      count = 0

      # 2. Selenium Setup (Headless Chrome)
      driver = None
      try:
          # è®¾ç½® Chrome é€‰é¡¹ï¼šæ— å¤´æ¨¡å¼å’Œå¿…è¦çš„å®‰å…¨å‚æ•°
          chrome_options = Options()
          chrome_options.add_argument("--headless")
          chrome_options.add_argument("--no-sandbox")
          chrome_options.add_argument("--disable-dev-shm-usage")
          chrome_options.add_argument("--window-size=1920,1080")
          # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ User-Agent
          chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
          
          # è‡ªåŠ¨ä¸‹è½½å’Œé…ç½® WebDriver
          service = Service(ChromeDriverManager().install())
          driver = webdriver.Chrome(service=service, options=chrome_options)
          # è®¾ç½®å…¨å±€é¡µé¢åŠ è½½è¶…æ—¶ä¸º 30 ç§’
          driver.set_page_load_timeout(30) 
          
          print("Selenium WebDriver initialized successfully (Headless Chrome).")
      except Exception as e:
          print(f"ERROR: Failed to initialize Selenium WebDriver: {e}", file=sys.stderr)
          # Set output to 0 and exit gracefully
          with open(GITHUB_OUTPUT, "a") as f:
              f.write(f"files_created=0\n")
          COMMIT_MESSAGE_FILE.write_text("Failed to initialize WebDriver.\n")
          sys.exit(1)


      # 3. Fetching Loop
      for url in urls:
          print(f"--- Processing URL: {url} ---")
          try:
              # æå–ä¸»æœºåä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ† (å»é™¤åè®®å’Œè·¯å¾„)
              hostname = urlparse(url).netloc.replace('.', '').replace(':', '')
              if not hostname:
                  print(f"Skipping invalid URL: {url}")
                  continue
                  
              filename = TARGET_DIR / f"v6_source_{hostname}.txt"

              # A. Load the page with 30s timeout
              driver.get(url)
              
              # å…³é”®ï¼šç­‰å¾…é¡µé¢å†…å®¹ï¼ˆå¦‚ body æ ‡ç­¾ï¼‰å‡ºç°ï¼Œæœ€å¤šç­‰å¾… 10 ç§’
              # è¿™æœ‰åŠ©äºç­‰å¾…åŠ¨æ€å†…å®¹å’Œ Cloudflare éªŒè¯é€šè¿‡
              WebDriverWait(driver, 10).until(
                  EC.presence_of_element_located((By.TAG_NAME, "body"))
              )
              
              # B. è·å–å®Œæ•´çš„é¡µé¢æºï¼ˆåŒ…å«æ‰€æœ‰åŠ è½½åçš„å†…å®¹ï¼ŒåŒ…æ‹¬ IPv6 åœ°å€ï¼‰
              page_source = driver.page_source
              
              # C. ä¿å­˜å†…å®¹
              if page_source and len(page_source) > 100: # æ£€æŸ¥å†…å®¹æ˜¯å¦å……å®
                  filename.write_text(page_source, encoding='utf-8')
                  
                  lines = len(page_source.splitlines())
                  print(f"âœ… Fetched approx {lines} lines, saved as {filename}")
                  
                  # Update commit details
                  with COMMIT_DETAILS_BODY_FILE.open("a") as f:
                      f.write(f"- Fetched approx {lines} lines from {hostname}\n")
                      
                  count += 1
              else:
                  print(f"âš ï¸ Fetched content empty or too short from {url}. Skipping.")
                  if filename.exists():
                      os.remove(filename)
                      
          except Exception as e:
              print(f"âŒ Failed to fetch content from {url} (Selenium error: {e}). Skipping.")
              
      # 4. Cleanup and Output
      if driver:
          driver.quit()
      
      print(f"Finished fetching. Total files created: {count}")
      
      # Set GITHUB_OUTPUT
      with open(GITHUB_OUTPUT, "a") as f:
          f.write(f"files_created={count}\n")
          
      # Prepare final commit message
      header_message = f"Auto update IPv6 sources ({count} files) via Selenium"
      body_content = COMMIT_DETAILS_BODY_FILE.read_text()
      COMMIT_MESSAGE_FILE.write_text(f"{header_message}\n\n{body_content}")

      PY

  - name: ğŸ’¾ Sync Files to Target Repository
    if: steps.fetch.outputs.files_created != '0'
    env:
      TARGET_URL: ${{ secrets.TARGET_REPO }}
      TARGET_PAT: ${{ secrets.TARGET_PAT }}
      TARGET_FOLDER: ${{ secrets.TARGET_FOLDER }}
      TEMP_DIR: ./ipv6_fetch_temp
      # MAX_IPV6_COUNT is inherited from job env
    run: |
      echo "Starting sync to target repository..."
      if [ -z "$TARGET_URL" ] || [ -z "$TARGET_PAT" ] || [ -z "$TARGET_FOLDER" ]; then
        echo "::error::TARGET_REPO / TARGET_PAT / TARGET_FOLDER not configured. Skipping."
        exit 0
      fi

      # 1. è§„èŒƒåŒ–ç›®æ ‡ URL
      TARGET_URL_RAW="${TARGET_URL}"
      if [[ $TARGET_URL_RAW == *"."* ]] || [[ $TARGET_URL_RAW == https://* ]]; then
        # å¯èƒ½æ˜¯å®Œæ•´çš„ URL
        TARGET_URL_HOST=$(echo "$TARGET_URL_RAW" | sed 's#https://##')
      else
        # å‡è®¾æ˜¯ 'owner/repo' æ ¼å¼
        TARGET_URL_HOST="github.com/${TARGET_URL_RAW}"
      fi

      TARGET_URL_WITH_PAT="https://${TARGET_PAT}@${TARGET_URL_HOST}"
      
      # 2. å…‹éš†ç›®æ ‡ä»“åº“
      git clone --single-branch "$TARGET_URL_WITH_PAT" target_repo_sync
      cd target_repo_sync
      # ä¿®å¤ 1: ä¼˜å…ˆåˆ‡æ¢åˆ° mainï¼Œä¸å­˜åœ¨æ—¶å†åˆ›å»º main
      git checkout main || git checkout -b main # ç¡®ä¿åœ¨ä¸»åˆ†æ”¯ä¸Šæ“ä½œ 

      mkdir -p "${TARGET_FOLDER}"
      git config core.fileMode false

      # 3. å¤åˆ¶æ–°æŠ“å–çš„æ–‡ä»¶
      cp -f ../${TEMP_DIR}/*.txt "./${TARGET_FOLDER}/" || true

      # 4. NEW: Generate myIPv6.txt inside target repo using Python (Updated Logic)
      echo "Running IPv6 aggregation script..."
      python3 - <<'PY'
      import os, sys, re, ipaddress, datetime
      from pathlib import Path
      
      # å¯¼å…¥ dateutil åº“ä»¥ç¡®ä¿å¯ç”¨æ€§
      try:
          from dateutil import parser as dateparser
      except ImportError:
          print("ERROR: 'python-dateutil' library required but not found.", file=sys.stderr)
          # å¦‚æœè¿è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜ä¸Šä¸€æ­¥å®‰è£…å¤±è´¥ï¼Œè„šæœ¬åº”é€€å‡º
          sys.exit(1)

      # ==========================================
      # 1. è·å–é…ç½®å’Œè®¾ç½®å½“å‰æ—¶é—´
      # ==========================================
      TARGET_FOLDER = os.environ.get('TARGET_FOLDER', '').strip()
      # ä½¿ç”¨ Shell ç¯å¢ƒå˜é‡è®¾ç½®çš„å€¼
      MAX_COUNT = int(os.environ.get('MAX_IPV6_COUNT', '500')) 
      
      # ã€ä¿®æ”¹ 1ï¼šç»Ÿä¸€ä½¿ç”¨å½“å‰è¿è¡Œæ—¶é—´ä½œä¸ºæ–° IP çš„æ—¶é—´æˆ³ã€‘
      now = datetime.datetime.now()
      print(f"Current Run Time for new IPs: {now.strftime('%Y-%m-%d %H:%M:%S')}")


      if not TARGET_FOLDER:
          print("ERROR: TARGET_FOLDER not set")
          sys.exit(1)

      repo_root = Path.cwd()
      target_dir = repo_root / TARGET_FOLDER
      
      if not target_dir.exists():
          print(f"Target dir {target_dir} does not exist. Creating...")
          target_dir.mkdir(parents=True, exist_ok=True)

      myfile = target_dir / 'myIPv6.txt'
      
      # å­˜å‚¨ç»“æ„: key=IP, value=(datetime_obj, source_string)
      ip_map = {}

      # ==========================================
      # 2. è¯»å–å·²å­˜åœ¨çš„ myIPv6.txt (å¢é‡æ›´æ–°æ ¸å¿ƒ)
      # ==========================================
      if myfile.exists():
          print(f"Read existing file: {myfile}")
          try:
              content = myfile.read_text(encoding='utf-8', errors='ignore')
              lines = content.splitlines()
              for line in lines:
                  # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                  if line.startswith('#') or line.startswith('-') or not line.strip() or "IPv6 | Time" in line:
                      continue
                  
                  # æ ¼å¼: IP | Time | Source
                  parts = line.split('|')
                  if len(parts) >= 2:
                      ip_str = parts[0].strip()
                      time_str = parts[1].strip()
                      src_str = parts[2].strip() if len(parts) > 2 else "Unknown"
                      
                      try:
                          # dateparser ç”¨äºè§£ææ—§æ–‡ä»¶ä¸­çš„æ—¶é—´
                          dt = dateparser.parse(time_str)
                          ip_map[ip_str] = (dt, src_str)
                      except:
                          pass # è§£æå¤±è´¥åˆ™ä¸¢å¼ƒæ—§æ•°æ®
          except Exception as e:
              print(f"Warning: Failed to parse existing file: {e}")

      print(f"Loaded {len(ip_map)} entries from existing file.")

      # ==========================================
      # 3. å¤„ç†æ–°æŠ“å–çš„ v6_source_*.txt æ–‡ä»¶
      # ==========================================
      
      files = sorted(target_dir.glob('v6_source_*.txt'))
      print(f"Processing {len(files)} new source files...")

      # æ–° IP çš„æ—¶é—´æˆ³ç»Ÿä¸€è®¾ç½®ä¸ºå½“å‰è¿è¡Œæ—¶é—´
      found_ts = now
      
      for f in files:
          source_name = f.name.replace('v6_source_','').replace('.txt','')
          text = f.read_text(encoding='utf-8', errors='ignore')
          
          # æå– IP
          tokens = set(re.findall(r'[0-9A-Fa-f:.]{2,}|[0-9A-Fa-f:]+', text))
          ips = set()
          for t in tokens:
              if ':' not in t: continue
              t_clean = t.strip(" ,;\"'()[]<>")
              try:
                  ip_obj = ipaddress.ip_address(t_clean)
                  if ip_obj.version == 6:
                      ips.add(t_clean)
              except:
                  continue

          # åˆå¹¶åˆ° ip_map 
          for ip in ips:
              prev = ip_map.get(ip)
              
              # ã€ä¿®æ”¹ 2ï¼šå»é‡é€»è¾‘ - å¦‚æœå·²å­˜åœ¨ï¼Œåˆ™ä¿ç•™æ—§çš„ï¼ˆæœ€æ—§çš„ï¼‰æ—¶é—´æˆ³ã€‘
              # åªæœ‰å½“ IP æ˜¯å…¨æ–°çš„æ—¶å€™æ‰æ·»åŠ ï¼ˆä½¿ç”¨å½“å‰æ—¶é—´ found_tsï¼‰
              if prev is None: 
                  ip_map[ip] = (found_ts, source_name)
              # å¦åˆ™ (prev is not None)ï¼Œä¸åšä»»ä½•æ“ä½œï¼Œä¿ç•™æ—§çš„ ip_map æ¡ç›®

      # ==========================================
      # 4. æ’åºã€æˆªæ–­ä¸å†™å…¥
      # ==========================================
      
      # æŒ‰æ—¶é—´å€’åºæ’åº (æœ€æ–°çš„åœ¨æœ€å‰)
      all_items = sorted(ip_map.items(), key=lambda kv: kv[1][0], reverse=True)
      
      total_found = len(all_items)
      
      # åº”ç”¨ Limit
      kept_items = all_items[:MAX_COUNT]
      
      # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
      if kept_items:
          times = [v[0] for _, v in kept_items]
          newest = max(times)
          oldest = min(times)
          time_range = f"{oldest.strftime('%Y-%m-%d %H:%M:%S')} ~ {newest.strftime('%Y-%m-%d %H:%M:%S')}"
      else:
          time_range = "N/A"

      unique_sources = set(v[1] for _, v in kept_items)
      generated_at = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

      header_lines = [
          "# IPv6 Summary Report",
          f"Total IPv6 (Merged Pool): {total_found}",
          f"Time Range: {time_range}",
          f"Source Count: {len(unique_sources)}",
          f"Generated At: {generated_at}",
          f"Applied Limit (MAX_IPV6_COUNT): {MAX_COUNT}",
          "-"*80,
          "IPv6 | Time | Source",
          "-"*80
      ]

      # å†™å…¥æ–‡ä»¶
      with myfile.open('w', encoding='utf-8') as fh:
          fh.write("\n".join(header_lines) + "\n")
          for ip, (dt, src) in kept_items:
              fh.write(f"{ip} | {dt.strftime('%Y-%m-%d %H:%M:%S')} | {src}\n")

      print(f"Done. Total merged: {total_found}. Kept top {len(kept_items)}. Saved to {myfile}")
      PY

    # 5. æäº¤å˜æ›´ (ä¼˜åŒ–åçš„ Git é€»è¾‘)
    git add "${TARGET_FOLDER}" || true

    # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„å˜æ›´
    if git diff-index --quiet HEAD --; then
      echo "No changes detected in the target folder. Skipping commit/push."
    else
      # ä¿®å¤ 2: ä½¿ç”¨ GITHUB_WORKSPACE ç»å¯¹è·¯å¾„å¼•ç”¨æäº¤ä¿¡æ¯æ–‡ä»¶
      COMMIT_FILE="${GITHUB_WORKSPACE}/final_commit_message.txt" 
      
      # æ£€æŸ¥å½“å‰åˆ†æ”¯å
      CURRENT_BRANCH=$(git symbolic-ref --short HEAD)

      if git commit -F "$COMMIT_FILE"; then
        echo "Commit success. Pushing to origin/${CURRENT_BRANCH}..."
        # æ¨é€åˆ°å½“å‰åˆ†æ”¯
        git push origin "$CURRENT_BRANCH"
      else
        # ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œé™¤éå‘ç”Ÿé‡å¤§é”™è¯¯
        echo "::warning::Git commit failed but files were changed. Check logs."
      fi
    fi

  - name: âœ… Done
    run: echo "IPv6 fetch and aggregation complete."
