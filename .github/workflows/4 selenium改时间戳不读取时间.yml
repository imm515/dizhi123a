name: 4 Selenium IPv6 æ”¹ç”¨æ—¶é—´æˆ³

on:
  workflow_dispatch:
    inputs:
      max_ipv6_count:
        description: 'èšåˆæ–‡ä»¶ myIPv6.txt ä¸­ä¿ç•™çš„æœ€å¤§ IPv6 æ¡æ•°ã€‚'
        required: false
        default: '500' # é»˜è®¤å€¼ 500
        type: string

jobs:
  fetch_and_sync_ipv6:
    runs-on: ubuntu-latest
    env:
      # âš ï¸ ç¡®ä¿åœ¨ TARGET_REPO ä»“åº“ä¸­æ­£ç¡®é…ç½®äº†ä»¥ä¸‹ Secrets:
      # IPV6_SOURCE_URLS: åŒ…å«è¦æŠ“å–çš„ IPv6 åˆ—è¡¨ URLï¼Œæ¯è¡Œä¸€ä¸ªã€‚
      # TARGET_REPO: ç›®æ ‡ä»“åº“çš„ owner/repo æ ¼å¼ï¼Œå¦‚ 'user/repo'ã€‚
      # TARGET_PAT: å…·æœ‰å¯¹ç›®æ ‡ä»“åº“å†™æƒé™çš„ Personal Access Tokenã€‚
      # TARGET_FOLDER: ç›®æ ‡ä»“åº“ä¸­å­˜æ”¾æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚ 'ipv6_lists'ã€‚
      TZ: Asia/Shanghai
      # è®¾ç½®èšåˆæ–‡ä»¶ä¿ç•™çš„æœ€å¤§ IPv6 æ¡æ•° (ä» input æˆ–é»˜è®¤å€¼è·å–)
      MAX_IPV6_COUNT: ${{ github.event.inputs.max_ipv6_count || '500' }}

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: âš™ï¸ Set Git Credentials
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      # --- å®‰è£… Python, Selenium å’Œ Chromeï¼ˆå¯èƒ½éœ€è¦ä¸€å®šæ—¶é—´ï¼‰ ---
      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: âš™ï¸ Install Chrome Browser and Dependencies
        run: |
          sudo apt-get update
          # å°è¯•å®‰è£… google-chrome-stableï¼ˆåœ¨æŸäº› runner ç¯å¢ƒå¯èƒ½å¤±è´¥ï¼‰
          sudo apt-get install -y google-chrome-stable || true
          # å¦‚æœ google-chrome-stable æœªå®‰è£…æˆåŠŸï¼Œå°½é‡å®‰è£… chromium-browser ä½œä¸ºå›é€€
          sudo apt-get install -y chromium-browser || true

      - name: âš™ï¸ Install Python Libraries (Selenium, WebDriver Manager & dateutil)
        run: |
          pip install --upgrade pip
          pip install selenium webdriver-manager python-dateutil

      # ---------------------------------------------
      - name: ğŸŒ Fetch IPv6 Addresses and Save (using Selenium)
        id: fetch
        env:
          URL_LIST: ${{ secrets.IPV6_SOURCE_URLS }}
          # æ³¨æ„ï¼šä¸è¦è¦†ç›– GITHUB_OUTPUTï¼ˆrunner ä¼šè‡ªåŠ¨æä¾›ï¼‰ï¼Œè¿™é‡Œåªä¼  URL_LIST
        run: |
          echo "Start fetching IPv6 sources using Selenium..."
          
          python3 - <<'PY'
          import os
          import sys
          from pathlib import Path
          from urllib.parse import urlparse
          
          # Selenium imports
          from selenium import webdriver
          from selenium.webdriver.chrome.service import Service
          from selenium.webdriver.chrome.options import Options
          from selenium.webdriver.support.ui import WebDriverWait
          from selenium.webdriver.support import expected_conditions as EC
          from selenium.webdriver.common.by import By
          from webdriver_manager.chrome import ChromeDriverManager
          
          # Config
          URL_LIST = os.environ.get('URL_LIST', '').strip()
          TARGET_DIR = Path('./ipv6_fetch_temp')
          COMMIT_DETAILS_BODY_FILE = Path("commit_details_body.txt")
          COMMIT_MESSAGE_FILE = Path("final_commit_message.txt")
          GITHUB_OUTPUT = os.environ.get('GITHUB_OUTPUT') # runner æä¾›çš„æ–‡ä»¶è·¯å¾„
          
          if not URL_LIST:
              print("WARNING: IPV6_SOURCE_URLS is empty. Skipping fetch operation.")
              if GITHUB_OUTPUT:
                  with open(GITHUB_OUTPUT, "a") as f:
                      f.write(f"files_created=0\n")
              COMMIT_MESSAGE_FILE.write_text("Skipped due to empty URL list.\n")
              sys.exit(0)
          
          TARGET_DIR.mkdir(parents=True, exist_ok=True)
          COMMIT_DETAILS_BODY_FILE.write_text("")
          
          urls = [u.strip() for u in URL_LIST.splitlines() if u.strip()]
          count = 0
          
          # Selenium headless setup
          driver = None
          try:
              chrome_options = Options()
              chrome_options.add_argument("--headless")
              chrome_options.add_argument("--no-sandbox")
              chrome_options.add_argument("--disable-dev-shm-usage")
              chrome_options.add_argument("--window-size=1920,1080")
              chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
              
              # å°è¯•ä½¿ç”¨ ChromeDriver Manager è‡ªåŠ¨å®‰è£…æˆ–æŸ¥æ‰¾é©±åŠ¨
              service = Service(ChromeDriverManager().install())
              driver = webdriver.Chrome(service=service, options=chrome_options)
              driver.set_page_load_timeout(30)
              print("Selenium WebDriver initialized successfully (Headless Chrome).")
          except Exception as e:
              # å¦‚æœ WebDriver åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ä¸ä½¿ç”¨ service (ä¾èµ–ç³»ç»Ÿå·²å®‰è£…çš„é©±åŠ¨æˆ–ç¯å¢ƒå˜é‡)
              try:
                  print(f"Initial WebDriver setup failed ({e}), trying fallback...")
                  driver = webdriver.Chrome(options=chrome_options)
                  driver.set_page_load_timeout(30)
                  print("Selenium WebDriver initialized successfully (Fallback).")
              except Exception as fallback_e:
                  print(f"ERROR: Failed to initialize Selenium WebDriver (Fallback failed): {fallback_e}", file=sys.stderr)
                  if GITHUB_OUTPUT:
                      with open(GITHUB_OUTPUT, "a") as f:
                          f.write(f"files_created=0\n")
                  COMMIT_MESSAGE_FILE.write_text("Failed to initialize WebDriver.\n")
                  sys.exit(1)
          
          # Fetch loop
          for url in urls:
              print(f"--- Processing URL: {url} ---")
              try:
                  hostname = urlparse(url).netloc.replace('.', '').replace(':', '')
                  if not hostname:
                      print(f"Skipping invalid URL: {url}")
                      continue
                  filename = TARGET_DIR / f"v6_source_{hostname}.txt"
                  
                  driver.get(url)
                  WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
                  page_source = driver.page_source
                  
                  if page_source and len(page_source) > 100:
                      filename.write_text(page_source, encoding='utf-8')
                      lines = len(page_source.splitlines())
                      print(f"âœ… Fetched approx {lines} lines, saved as {filename}")
                      with COMMIT_DETAILS_BODY_FILE.open("a") as f:
                          f.write(f"- Fetched approx {lines} lines from {hostname}\n")
                      count += 1
                  else:
                      print(f"âš ï¸ Fetched content empty or too short from {url}. Skipping.")
                      if filename.exists():
                          os.remove(filename)
              except Exception as e:
                  print(f"âŒ Failed to fetch content from {url} (Selenium error: {e}). Skipping.")
          
          if driver:
              driver.quit()
          
          print(f"Finished fetching. Total files created: {count}")
          
          # Set output for subsequent steps via GITHUB_OUTPUT file (runner æä¾›)
          if GITHUB_OUTPUT:
              with open(GITHUB_OUTPUT, "a") as f:
                  f.write(f"files_created={count}\n")
          
          header_message = f"Auto update IPv6 sources ({count} files) via Selenium"
          body_content = COMMIT_DETAILS_BODY_FILE.read_text()
          COMMIT_MESSAGE_FILE.write_text(f"{header_message}\n\n{body_content}")
          PY

      - name: ğŸ’¾ Sync Files to Target Repository
        if: steps.fetch.outputs.files_created != '0'
        env:
          TARGET_URL: ${{ secrets.TARGET_REPO }}
          TARGET_PAT: ${{ secrets.TARGET_PAT }}
          TARGET_FOLDER: ${{ secrets.TARGET_FOLDER }}
          TEMP_DIR: ./ipv6_fetch_temp
          # MAX_IPV6_COUNT is inherited from job env
        run: |
          echo "Starting sync to target repository..."
          if [ -z "$TARGET_URL" ] || [ -z "$TARGET_PAT" ] || [ -z "$TARGET_FOLDER" ]; then
            echo "::error::TARGET_REPO / TARGET_PAT / TARGET_FOLDER not configured. Skipping."
            exit 0
          fi

          # è§„èŒƒåŒ–ç›®æ ‡ URLï¼ˆæ”¯æŒ owner/repo æˆ–å®Œæ•´ URLï¼‰
          TARGET_URL_RAW="${TARGET_URL}"
          if [[ $TARGET_URL_RAW == *"."* ]] || [[ $TARGET_URL_RAW == https://* ]]; then
            TARGET_URL_HOST=$(echo "$TARGET_URL_RAW" | sed 's#https://##' | sed 's#http://##')
          else
            TARGET_URL_HOST="github.com/${TARGET_URL_RAW}"
          fi

          TARGET_URL_WITH_PAT="https://${TARGET_PAT}@${TARGET_URL_HOST}"
          
          # å…‹éš†ç›®æ ‡ä»“åº“
          git clone --single-branch "$TARGET_URL_WITH_PAT" target_repo_sync
          cd target_repo_sync
          git checkout main || git checkout -b main

          mkdir -p "${TARGET_FOLDER}"
          git config core.fileMode false

          # å¤åˆ¶æ–°æŠ“å–çš„æ–‡ä»¶
          cp -f ../${TEMP_DIR}/*.txt "./${TARGET_FOLDER}/" || true

          # ç”Ÿæˆå¹¶æ›´æ–° myIPv6.txtï¼ˆèšåˆé€»è¾‘ï¼‰
          echo "Running IPv6 aggregation script..."
          python3 - <<'PY'
          import os, sys, re, ipaddress, datetime
          from pathlib import Path

          try:
              # å¼•å…¥ dateutil.tz ç”¨äºæ—¶åŒºå¤„ç†
              from dateutil import parser as dateparser, tz 
          except ImportError:
              print("ERROR: 'python-dateutil' library required but not found.", file=sys.stderr)
              sys.exit(1)

          # 1. è·å–é…ç½®å’Œå½“å‰æ—¶é—´ï¼ˆç»Ÿä¸€ä½¿ç”¨ä¸Šæµ·æ—¶é—´ UTC+8ï¼‰
          TARGET_FOLDER = os.environ.get('TARGET_FOLDER', '').strip()
          MAX_COUNT = int(os.environ.get('MAX_IPV6_COUNT', '500'))
          
          # å®šä¹‰ä¸Šæµ·æ—¶åŒº
          SHANGHAI_TZ = tz.gettz('Asia/Shanghai')

          # è·å–å½“å‰çš„ä¸Šæµ·æ—¶é—´ï¼ˆå¸¦æ—¶åŒºä¿¡æ¯ï¼‰
          now_shanghai_aware = datetime.datetime.now(SHANGHAI_TZ)
          # å°†å…¶è½¬æ¢ä¸ºæ— æ—¶åŒºä¿¡æ¯çš„ naive datetime å¯¹è±¡ï¼Œä½†å€¼ä»£è¡¨ä¸Šæµ·æ—¶é—´
          now = now_shanghai_aware.replace(tzinfo=None) 
          
          print(f"Current Run Time for new IPs (Shanghai Time, Naive): {now.strftime('%Y-%m-%d %H:%M:%S')}")

          if not TARGET_FOLDER:
              print("ERROR: TARGET_FOLDER not set")
              sys.exit(1)

          repo_root = Path.cwd()
          target_dir = repo_root / TARGET_FOLDER
          target_dir.mkdir(parents=True, exist_ok=True)

          myfile = target_dir / 'myIPv6.txt'
          ip_map = {} # key=IP (canonical form), value=(datetime_obj (Shanghai naive), source)

          # helper: è§„èŒƒåŒ– datetime å¯¹è±¡ä¸ºä¸Šæµ·æ—¶é—´çš„ naive å¯¹è±¡
          def normalize_to_shanghai_naive(dt):
              if dt is None:
                  return None
              try:
                  # å¦‚æœæ˜¯å¸¦æ—¶åŒºçš„ aware å¯¹è±¡ï¼Œå…ˆè½¬æ¢åˆ°ä¸Šæµ·æ—¶åŒº
                  if dt.tzinfo is not None:
                      dt_shanghai = dt.astimezone(SHANGHAI_TZ)
                      # ç§»é™¤æ—¶åŒºä¿¡æ¯ï¼Œä½¿å…¶æˆä¸º Shanghai naive
                      return dt_shanghai.replace(tzinfo=None)
                  
                  # å¦‚æœæ˜¯ naive å¯¹è±¡ï¼Œæˆ‘ä»¬å‡å®šå®ƒå·²ç»æ˜¯ä¸Šæµ·æ—¶é—´
                  return dt
              except Exception:
                  return None

          # 2. è¯»å–å·²å­˜åœ¨çš„ myIPv6.txtï¼ˆè§£ææ—§æ—¶é—´å¹¶è§„èŒƒåŒ–åˆ°ä¸Šæµ·æ—¶é—´ï¼‰
          if myfile.exists():
              print(f"Read existing file: {myfile}")
              try:
                  content = myfile.read_text(encoding='utf-8', errors='ignore')
                  lines = content.splitlines()
                  for line in lines:
                      if line.startswith('#') or line.startswith('-') or not line.strip() or "IPv6 | Time" in line:
                          continue
                      parts = line.split('|')
                      if len(parts) >= 2:
                          ip_str = parts[0].strip()
                          time_str = parts[1].strip()
                          src_str = parts[2].strip() if len(parts) > 2 else "Unknown"
                          try:
                              # è§£æ IP æ—¶ï¼Œå°†å…¶è½¬æ¢ä¸ºè§„èŒƒåŒ–å½¢å¼ä½œä¸ºå­—å…¸é”®
                              ip_obj = ipaddress.ip_address(ip_str)
                              canonical_ip = ip_obj.compressed 
                              
                              dt = dateparser.parse(time_str)
                              # è§„èŒƒåŒ–åˆ°ä¸Šæµ·æ—¶é—´ naive
                              dt = normalize_to_shanghai_naive(dt)
                              if dt and 2000 <= dt.year <= 2035:
                                  ip_map[canonical_ip] = (dt, src_str)
                          except Exception:
                              # å¿½ç•¥æ— æ³•è§£æçš„ IP æˆ–æ—¶é—´
                              pass
              except Exception as e:
                  print(f"Warning: Failed to parse existing file: {e}")

          print(f"Loaded {len(ip_map)} entries from existing file.")

          # 3. å¤„ç†æ–°æŠ“å–çš„ v6_source_*.txt æ–‡ä»¶ï¼ˆç»Ÿä¸€ä½¿ç”¨å½“å‰ä¸Šæµ·æ—¶é—´ä½œä¸ºæ–° IP çš„æ—¶é—´æˆ³ï¼‰
          files = sorted(target_dir.glob('v6_source_*.txt'))
          print(f"Processing {len(files)} new source files...")

          # ç»Ÿä¸€ä½¿ç”¨å½“å‰è¿è¡Œæ—¶é—´ï¼ˆä¸Šæµ·æ—¶é—´ naiveï¼‰ä½œä¸ºæ–° IP çš„æ—¶é—´æˆ³
          found_ts = now

          for f in files:
              source_name = f.name.replace('v6_source_','').replace('.txt','')
              text = f.read_text(encoding='utf-8', errors='ignore')

              # æå–å¯èƒ½çš„ IPv6ï¼ˆç²—ç•¥è¿‡æ»¤åç”¨ ipaddress éªŒè¯ï¼‰
              tokens = set(re.findall(r'[0-9A-Fa-f:.]{2,}|[0-9A-Fa-f:]+', text))
              ips_canonical = set()
              for t in tokens:
                  if ':' not in t:
                      continue
                  t_clean = t.strip(" ,;\"'()[]<>")
                  try:
                      ip_obj = ipaddress.ip_address(t_clean)
                      if ip_obj.version == 6:
                          # ä½¿ç”¨æ ‡å‡†å‹ç¼©å½¢å¼ä½œä¸ºé›†åˆå…ƒç´  (å·²åœ¨ä¸Šæ¬¡æ›´æ”¹ä¸­å®ç°)
                          canonical_ip = ip_obj.compressed
                          ips_canonical.add(canonical_ip)
                  except Exception:
                      continue

              for ip in ips_canonical:
                  prev = ip_map.get(ip)
                  # å¦‚æœä¹‹å‰ä¸å­˜åœ¨ï¼Œåˆ™ä»¥ found_tsï¼ˆnowï¼‰åŠ å…¥ï¼›å·²å­˜åœ¨åˆ™ä¿ç•™æ—§æ—¶é—´
                  # ç”±äº IP å·²ç»è§„èŒƒåŒ–ï¼Œè¿™é‡Œçš„æŸ¥æ‰¾æ˜¯å‡†ç¡®çš„å»é‡
                  if prev is None:
                      ip_map[ip] = (found_ts, source_name)

          # 4. æ’åºã€æˆªæ–­ä¸å†™å…¥ï¼ˆæŒ‰æ—¶é—´å€’åºï¼Œæœ€æ–°åœ¨å‰ï¼‰
          all_items = sorted(ip_map.items(), key=lambda kv: kv[1][0], reverse=True)
          total_found = len(all_items)
          kept_items = all_items[:MAX_COUNT]

          if kept_items:
              times = [v[0] for _, v in kept_items]
              newest = max(times)
              oldest = min(times)
              # æ—¶é—´èŒƒå›´æ˜¾ç¤ºä¸Šæµ·æ—¶é—´
              time_range = f"{oldest.strftime('%Y-%m-%d %H:%M:%S')} ~ {newest.strftime('%Y-%m-%d %H:%M:%S')}"
          else:
              time_range = "N/A"

          unique_sources = set(v[1] for _, v in kept_items)
          # ç”Ÿæˆæ—¶é—´æ˜¾ç¤ºä¸Šæµ·æ—¶é—´
          generated_at = now.strftime('%Y-%m-%d %H:%M:%S')

          header_lines = [
              "# IPv6 Summary Report",
              "# NOTE: All times are Shanghai Time (UTC+8)",
              f"Total IPv6 (Merged Pool): {total_found}",
              f"Time Range: {time_range}",
              f"Source Count: {len(unique_sources)}",
              f"Generated At (Shanghai Time): {generated_at}",
              f"Applied Limit (MAX_IPV6_COUNT): {MAX_COUNT}",
              "-"*80,
              "IPv6 | Time | Source",
              "-"*80
          ]

          with myfile.open('w', encoding='utf-8') as fh:
              fh.write("\n".join(header_lines) + "\n")
              for ip, (dt, src) in kept_items:
                  # å†™å…¥æ—¶ï¼Œip å·²ç»æ˜¯è§„èŒƒåŒ–åçš„å‹ç¼©å½¢å¼ï¼Œdt æ˜¯ä¸Šæµ·æ—¶é—´ naive
                  fh.write(f"{ip} | {dt.strftime('%Y-%m-%d %H:%M:%S')} | {src}\n")

          print(f"Done. Total merged: {total_found}. Kept top {len(kept_items)}. Saved to {myfile}")
          PY

          # æäº¤å˜æ›´
          git add "${TARGET_FOLDER}" || true

          if git diff-index --quiet HEAD --; then
            echo "No changes detected in the target folder. Skipping commit/push."
          else
            COMMIT_FILE="${GITHUB_WORKSPACE}/final_commit_message.txt"
            CURRENT_BRANCH=$(git symbolic-ref --short HEAD)
            if git commit -F "$COMMIT_FILE"; then
              echo "Commit success. Pushing to origin/${CURRENT_BRANCH}..."
              git push origin "$CURRENT_BRANCH"
            else
              echo "::warning::Git commit failed but files was changed. Check logs."
            fi
          fi

      - name: âœ… Done
        run: echo "IPv6 fetch and aggregation complete."