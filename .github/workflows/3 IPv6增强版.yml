name: 3 IPv6 Source Fetcher (Enhanced)

on:
  workflow_dispatch:

jobs:
  fetch_and_sync_ipv6:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ‚öôÔ∏è Set Git Credentials
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: üåê Fetch IPv6 Addresses and Save
        id: fetch
        env:
          URL_LIST: ${{ secrets.IPV6_SOURCE_URLS }}
        run: |
          echo "Start fetching IPv6 sources..."
          TARGET_DIR=./ipv6_fetch_temp
          mkdir -p "$TARGET_DIR"
          COMMIT_DETAILS_BODY_FILE="commit_details_body.txt"
          COMMIT_MESSAGE_FILE="final_commit_message.txt"
          > "$COMMIT_DETAILS_BODY_FILE"
          > "$COMMIT_MESSAGE_FILE"

          if [ -z "$URL_LIST" ]; then
            echo "WARNING: IPV6_SOURCE_URLS is empty. Skipping fetch operation."
            echo "files_created=0" >> $GITHUB_OUTPUT
            echo "Skipped due to empty URL list." > "$COMMIT_MESSAGE_FILE"
            exit 0
          fi

          URL_LIST_CLEANED=$(echo "$URL_LIST" | tr -d '\r')
          mapfile -t URLs <<< "$URL_LIST_CLEANED"
          COUNT=0

          for URL in "${URLs[@]}"; do
            URL=$(echo "$URL" | tr -d '[:space:]')
            if [ -z "$URL" ]; then
              continue
            fi
            HOSTNAME=$(echo "$URL" | sed -E 's/^\w+:\/\///' | cut -d '/' -f 1 | tr -d '.')
            FILENAME="${TARGET_DIR}/v6_source_${HOSTNAME}.txt"
            echo "--- Processing URL: $URL ---"
            if curl -s -L "$URL" > "$FILENAME"; then
              echo "" >> "$FILENAME"
              LINES=$(wc -l < "$FILENAME" || echo 0)
              if [ "$LINES" -gt 0 ]; then
                echo "‚úÖ Fetched $LINES lines, saved as $FILENAME"
                echo "- Fetched ${LINES} lines from ${HOSTNAME}" >> "$COMMIT_DETAILS_BODY_FILE"
                COUNT=$((COUNT + 1))
              else
                echo "‚ö†Ô∏è Fetched content empty from $URL. Removing file."
                rm -f "$FILENAME"
              fi
            else
              echo "‚ùå Failed to fetch content from $URL. Skipping."
              rm -f "$FILENAME"
            fi
          done

          echo "Finished fetching. Total files created: $COUNT"
          echo "files_created=$COUNT" >> $GITHUB_OUTPUT
          HEADER_MESSAGE="Auto update IPv6 sources (${COUNT} files)"
          (echo "$HEADER_MESSAGE"; echo ""; cat "$COMMIT_DETAILS_BODY_FILE") > "$COMMIT_MESSAGE_FILE"

      - name: üíæ Sync Files to Target Repository
          if: steps.fetch.outputs.files_created != '0'
          env:
            TARGET_URL: ${{ secrets.TARGET_REPO }}
            TARGET_PAT: ${{ secrets.TARGET_PAT }}
            TARGET_FOLDER: ${{ secrets.TARGET_FOLDER }}
            TEMP_DIR: ./ipv6_fetch_temp
            # --- ‰øÆÊîπÈÖçÁΩÆÔºöÂú®Ê≠§Â§ÑËÆæÁΩÆÊúÄÂ§ß‰øùÁïôÊï∞Èáè ---
            MAX_IPV6_COUNT: 30
          run: |
            echo "Starting sync to target repository..."
            if [ -z "$TARGET_URL" ] || [ -z "$TARGET_PAT" ] || [ -z "$TARGET_FOLDER" ]; then
              echo "::error::TARGET_REPO / TARGET_PAT / TARGET_FOLDER not configured. Skipping."
              exit 0
            fi

            TARGET_URL_RAW="${TARGET_URL}"
            TARGET_URL_HOST=""
            if [[ $TARGET_URL_RAW == *"."* ]] || [[ $TARGET_URL_RAW == https://* ]]; then
              TARGET_URL_HOST=$(echo "$TARGET_URL_RAW" | sed 's#https://##')
            else
              TARGET_URL_HOST="github.com/${TARGET_URL_RAW}"
            fi

            TARGET_URL_WITH_PAT="https://${TARGET_PAT}@${TARGET_URL_HOST}"

            # clone target repo
            git clone "$TARGET_URL_WITH_PAT" target_repo_sync
            cd target_repo_sync

            mkdir -p "${TARGET_FOLDER}"
            git config core.fileMode false

            # copy fetched files
            cp -f ../${TEMP_DIR}/*.txt "./${TARGET_FOLDER}/" || true

            # --- NEW: Generate myIPv6.txt inside target repo using Python ---
            echo "Running IPv6 aggregation script..."
            python3 - <<'PY'
            import os, sys, re, ipaddress, datetime
            from pathlib import Path
            from dateutil import parser as dateparser

            # 1. Ëé∑ÂèñÈÖçÁΩÆ (Áªü‰∏ÄÂú®ËøôÈáå‰øÆÊîπÈªòËÆ§ÂÄº)
            TARGET_FOLDER = os.environ.get('TARGET_FOLDER', '').strip()
            # Â¶ÇÊûúÁéØÂ¢ÉÂèòÈáèÊ≤°ËÆæÁΩÆÔºåÈªòËÆ§Áªô 30
            MAX_COUNT = int(os.environ.get('MAX_IPV6_COUNT', '30'))

            if not TARGET_FOLDER:
                print("ERROR: TARGET_FOLDER not set")
                sys.exit(1)

            repo_root = Path.cwd()
            target_dir = repo_root / TARGET_FOLDER
            
            if not target_dir.exists():
                print(f"Target dir {target_dir} does not exist. Creating...")
                target_dir.mkdir(parents=True, exist_ok=True)

            myfile = target_dir / 'myIPv6.txt'
            
            # Â≠òÂÇ®ÁªìÊûÑ: key=IP, value=(datetime_obj, source_string)
            ip_map = {}

            # ==========================================
            # 2. ËØªÂèñÂ∑≤Â≠òÂú®ÁöÑ myIPv6.txt (Â¢ûÈáèÊõ¥Êñ∞Ê†∏ÂøÉ)
            # ==========================================
            if myfile.exists():
                print(f"Read existing file: {myfile}")
                try:
                    content = myfile.read_text(encoding='utf-8', errors='ignore')
                    lines = content.splitlines()
                    for line in lines:
                        # Ë∑≥ËøáÊ≥®ÈáäÂíåÁ©∫Ë°å
                        if line.startswith('#') or line.startswith('-') or not line.strip() or "IPv6 | Time" in line:
                            continue
                        
                        # Ê†ºÂºè: IP | Time | Source
                        parts = line.split('|')
                        if len(parts) >= 2:
                            ip_str = parts[0].strip()
                            time_str = parts[1].strip()
                            src_str = parts[2].strip() if len(parts) > 2 else "Unknown"
                            
                            try:
                                dt = dateparser.parse(time_str)
                                ip_map[ip_str] = (dt, src_str)
                            except:
                                pass # Ëß£ÊûêÂ§±Ë¥•Âàô‰∏¢ÂºÉÊóßÊï∞ÊçÆ
                except Exception as e:
                    print(f"Warning: Failed to parse existing file: {e}")

            print(f"Loaded {len(ip_map)} entries from existing file.")

            # ==========================================
            # 3. Â§ÑÁêÜÊñ∞ÊäìÂèñÁöÑ v6_source_*.txt Êñá‰ª∂
            # ==========================================
            # helper: extract possible timestamps
            timestamp_patterns = [
                r'\d{4}[-/]\d{1,2}[-/]\d{1,2}[ T]\d{1,2}:\d{2}:\d{2}', 
                r'\d{4}[-/]\d{1,2}[-/]\d{1,2}[ T]\d{1,2}:\d{2}', 
                r'\d{2,4}[-/]\d{1,2}[-/]\d{1,2}',
                r'\w{3,9}\s+\d{1,2},\s*\d{4}\s*\d{0,2}:\d{0,2}:\d{0,2}',
            ]

            files = sorted(target_dir.glob('v6_source_*.txt'))
            print(f"Processing {len(files)} new source files...")

            for f in files:
                source_name = f.name.replace('v6_source_','').replace('.txt','')
                text = f.read_text(encoding='utf-8', errors='ignore')
                
                # ÊèêÂèñ IP
                tokens = set(re.findall(r'[0-9A-Fa-f:.]{2,}|[0-9A-Fa-f:]+', text))
                ips = set()
                for t in tokens:
                    if ':' not in t: continue
                    t_clean = t.strip(" ,;\"'()[]<>")
                    try:
                        ip_obj = ipaddress.ip_address(t_clean)
                        if ip_obj.version == 6:
                            ips.add(t_clean)
                    except:
                        continue

                # ÊèêÂèñÊó∂Èó¥ (Â¶ÇÊûúÊ≤°ÊúâÊâæÂà∞Êó∂Èó¥Ôºå‰ΩøÁî®Êñá‰ª∂‰øÆÊîπÊó∂Èó¥)
                found_ts = None
                for pat in timestamp_patterns:
                    m = re.search(pat, text)
                    if m:
                        try:
                            found_ts = dateparser.parse(m.group(0), fuzzy=True)
                            break
                        except:
                            continue
                
                if found_ts is None:
                    found_ts = datetime.datetime.fromtimestamp(f.stat().st_mtime)

                # ÂêàÂπ∂Âà∞ ip_map (Â¶ÇÊûúIPÂ∑≤Â≠òÂú®Ôºå‰øùÁïôÊó∂Èó¥ËæÉÊñ∞ÁöÑ)
                for ip in ips:
                    prev = ip_map.get(ip)
                    # ÈÄªËæëÔºöÂ¶ÇÊûú‰πãÂâç‰∏çÂ≠òÂú®ÔºåÊàñËÄÖÊñ∞ÊäìÂèñÁöÑÊó∂Èó¥ÊØîÊóßÁöÑÊó∂Èó¥Êñ∞ÔºåÂàôÊõ¥Êñ∞
                    if prev is None or found_ts >= prev[0]:
                        ip_map[ip] = (found_ts, source_name)

            # ==========================================
            # 4. ÊéíÂ∫è„ÄÅÊà™Êñ≠‰∏éÂÜôÂÖ•
            # ==========================================
            
            # ÊåâÊó∂Èó¥ÂÄíÂ∫èÊéíÂ∫è (ÊúÄÊñ∞ÁöÑÂú®ÊúÄÂâç)
            all_items = sorted(ip_map.items(), key=lambda kv: kv[1][0], reverse=True)
            
            total_found = len(all_items)
            
            # Â∫îÁî® Limit (30)
            kept_items = all_items[:MAX_COUNT]
            
            # ÁîüÊàêÁªüËÆ°‰ø°ÊÅØ
            if kept_items:
                times = [v[0] for _, v in kept_items]
                newest = max(times)
                oldest = min(times)
                time_range = f"{oldest.strftime('%Y-%m-%d %H:%M:%S')} ~ {newest.strftime('%Y-%m-%d %H:%M:%S')}"
            else:
                time_range = "N/A"

            unique_sources = set(v[1] for _, v in kept_items)
            generated_at = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            header_lines = [
                "# IPv6 Summary Report",
                f"Total IPv6 (Merged Pool): {total_found}",
                f"Time Range: {time_range}",
                f"Source Count: {len(unique_sources)}",
                f"Generated At: {generated_at}",
                f"Applied Limit (MAX_IPV6_COUNT): {MAX_COUNT}",
                "-"*80,
                "IPv6 | Time | Source",
                "-"*80
            ]

            # ÂÜôÂÖ•Êñá‰ª∂
            with myfile.open('w', encoding='utf-8') as fh:
                fh.write("\n".join(header_lines) + "\n")
                for ip, (dt, src) in kept_items:
                    fh.write(f"{ip} | {dt.strftime('%Y-%m-%d %H:%M:%S')} | {src}\n")

            print(f"Done. Total merged: {total_found}. Kept top {len(kept_items)}. Saved to {myfile}")
            PY

            # commit changes
            git add "${TARGET_FOLDER}" || true

            # prepare commit message file
            COMMIT_FILE="../final_commit_message.txt"
            if [ -f "$COMMIT_FILE" ]; then
              if git commit -F "$COMMIT_FILE" --allow-empty-message; then
                echo "Commit success."
                git push origin main
              else
                echo "Git commit failed or nothing to commit."
                git push origin main || true
              fi
            else
              git commit -m "Auto update IPv6 sources and aggregated myIPv6.txt" || true
              git push origin main || true
            fi

      - name: ‚úÖ Done
        run: echo "IPv6 fetch and aggregation complete."

